{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5924652e-416e-445d-a240-71564a8fa42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 09:17:27.118675: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 09:17:28.714470: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-09 09:17:29.425776: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/isaac/compilers/intel/oneAPI_2021.2.0/mpi/latest/libfabric/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/mpi/latest/lib/release:/sw/isaac/compilers/intel/oneAPI_2021.2.0/mpi/latest/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/ippcp/latest/lib/intel64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/ipp/latest/lib/intel64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/itac/latest/slib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/mkl/latest/lib/intel64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/lib/x64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/lib/emu:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/compiler/lib/intel64_lin:/sw/isaac/compilers/intel/oneAPI_2021.2.0/debugger/latest/dep/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/debugger/latest/libipt/intel64/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/debugger/latest/gdb/intel64/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/tbb/latest/lib/intel64/gcc4.8\n",
      "2022-12-09 09:17:29.425793: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-09 09:17:29.640801: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-09 09:17:34.388212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/isaac/compilers/intel/oneAPI_2021.2.0/mpi/latest/libfabric/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/mpi/latest/lib/release:/sw/isaac/compilers/intel/oneAPI_2021.2.0/mpi/latest/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/ippcp/latest/lib/intel64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/ipp/latest/lib/intel64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/itac/latest/slib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/mkl/latest/lib/intel64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/lib/x64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/lib/emu:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/compiler/lib/intel64_lin:/sw/isaac/compilers/intel/oneAPI_2021.2.0/debugger/latest/dep/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/debugger/latest/libipt/intel64/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/debugger/latest/gdb/intel64/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/tbb/latest/lib/intel64/gcc4.8\n",
      "2022-12-09 09:17:34.390076: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/isaac/compilers/intel/oneAPI_2021.2.0/mpi/latest/libfabric/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/mpi/latest/lib/release:/sw/isaac/compilers/intel/oneAPI_2021.2.0/mpi/latest/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/ippcp/latest/lib/intel64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/ipp/latest/lib/intel64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/itac/latest/slib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/mkl/latest/lib/intel64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/lib/x64:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/lib/emu:/sw/isaac/compilers/intel/oneAPI_2021.2.0/compiler/latest/linux/compiler/lib/intel64_lin:/sw/isaac/compilers/intel/oneAPI_2021.2.0/debugger/latest/dep/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/debugger/latest/libipt/intel64/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/debugger/latest/gdb/intel64/lib:/sw/isaac/compilers/intel/oneAPI_2021.2.0/tbb/latest/lib/intel64/gcc4.8\n",
      "2022-12-09 09:17:34.390085: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.ensemble import RandomSurvivalForest, GradientBoostingSurvivalAnalysis\n",
    "from sksurv.svm import FastKernelSurvivalSVM\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sklearn.impute import KNNImputer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow import keras as ks\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from sklearn.linear_model import Lasso\n",
    "from sksurv.util import Surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8665d058-0786-4c7f-9a29-32747a37f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNA(df, k_neighbors=10, index=[]):\n",
    "    if not list(index):\n",
    "        index = df.index\n",
    "    \n",
    "    X = df.values\n",
    "    knn = KNNImputer(n_neighbors=k_neighbors)\n",
    "    X_imp = knn.fit_transform(X)\n",
    "    \n",
    "    df_imp = pd.DataFrame(X_imp, columns=df.columns)\n",
    "    df_imp.set_index(index, inplace=True)\n",
    "    \n",
    "    return df_imp\n",
    "\n",
    "def minmax_scale(train, test):\n",
    "    xtrain_scaled = pd.DataFrame(MinMaxScaler().fit_transform(train), columns=train.columns)\n",
    "    xtest_scaled = pd.DataFrame(MinMaxScaler().fit_transform(test), columns=test.columns)\n",
    "    return xtrain_scaled, xtest_scaled  \n",
    "\n",
    "def split_and_scale_data(features, labels, test_size=0.3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=5, stratify=labels)\n",
    "    X_train_scaled, X_test_scaled = minmax_scale(X_train, X_test)\n",
    "    X_train_scaled.set_index(X_train.index, inplace=True)\n",
    "    X_test_scaled.set_index(X_test.index, inplace=True)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def make_structured_array(event, time):\n",
    "    return Surv.from_arrays(event, time)\n",
    "\n",
    "class Autoencoder(ks.models.Model):\n",
    "    def __init__(self, actual_dim, latent_dim, activation, loss, optimizer):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.encoder = ks.Sequential([\n",
    "        ks.layers.Flatten(),\n",
    "        ks.layers.Dense(latent_dim, activation=activation),\n",
    "        ])\n",
    "\n",
    "        self.decoder = ks.Sequential([\n",
    "        ks.layers.Dense(actual_dim, activation=activation),\n",
    "        ])\n",
    "\n",
    "        self.compile(loss=loss, optimizer=optimizer, metrics=[ks.metrics.BinaryAccuracy(name='accuracy')])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "def create_AE(actual_dim=1, latent_dim=100, activation='relu', loss='MAE', optimizer='Adam'):\n",
    "    return Autoencoder(actual_dim, latent_dim, activation, loss, optimizer)\n",
    "\n",
    "def run_AE(X_train_scaled, X_test_scaled, param_grid=None):\n",
    "\n",
    "    if param_grid == None:\n",
    "        param_grid = {\n",
    "            'actual_dim' : [len(X_train_scaled.columns)],\n",
    "            'latent_dim' : [100, 200, 500],\n",
    "            'activation' : ['relu', 'sigmoid', 'tanh'],\n",
    "            'loss' : ['MAE', 'binary_crossentropy'],\n",
    "            'optimizer' : ['SGD', 'Adam']\n",
    "        }\n",
    "\n",
    "    model = KerasClassifier(build_fn=create_AE, epochs=10, verbose=0)\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        verbose=3\n",
    "    )\n",
    "\n",
    "    result = grid.fit(X_train_scaled, X_train_scaled, validation_data=(X_test_scaled, X_test_scaled))\n",
    "    params = grid.best_params_\n",
    "    autoencoder = create_AE(**params)\n",
    "\n",
    "    try:\n",
    "        encoder_layer = autoencoder.encoder\n",
    "    except:\n",
    "        exit\n",
    "\n",
    "    AE_train = pd.DataFrame(encoder_layer.predict(X_train_scaled))\n",
    "    AE_train.add_prefix('feature_')\n",
    "    AE_test = pd.DataFrame(encoder_layer.predict(X_test_scaled))\n",
    "    AE_test.add_prefix('feature_')\n",
    "\n",
    "    return AE_train, AE_test\n",
    "\n",
    "def run_LASSO(X_train_scaled, y_train, param_grid = None):\n",
    "    if param_grid == None:\n",
    "        param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "    search = GridSearchCV(estimator = Lasso(),\n",
    "                          param_grid = param_grid,\n",
    "                          cv = 5,\n",
    "                          scoring=\"neg_mean_squared_error\",\n",
    "                          verbose=3\n",
    "                          )\n",
    "\n",
    "    search.fit(X_train_scaled, y_train)\n",
    "    coefficients = search.best_estimator_.coef_\n",
    "    importance = np.abs(coefficients)\n",
    "    keep = np.array(X_train_scaled.columns)[importance != 0]\n",
    "\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eaecedc-c79a-4c71-b112-659daf73c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = sys.argv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdaa0cc7-c620-4b2a-828d-024746c1f7b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f/train/readcounts_training.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2219581/252693575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreads_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/train/readcounts_training.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpheno_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/train/pheno_training.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/base-venv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/base-venv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/base-venv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/base-venv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/base-venv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/base-venv/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/base-venv/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/base-venv/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f/train/readcounts_training.csv'"
     ]
    }
   ],
   "source": [
    "reads_train = pd.read_csv(INPUT_DIR+'/train/readcounts_training.csv', index_col=0)\n",
    "pheno_train = pd.read_csv(INPUT_DIR+'/train/pheno_training.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1167c-f465-4d65-b82e-562832c30134",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_train = pheno_train.dropna(subset=['Event', 'Event_time']) #should not try to correct these\n",
    "reads_train = reads_train.T\n",
    "train_ids = pheno_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af31f93-f01c-4994-89ad-3f9edd4fa2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_test = pd.read_csv(INPUT_DIR+'/test/readcounts_test.csv', index_col=0)\n",
    "pheno_test = pd.read_csv(INPUT_DIR+'/test/pheno_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c8cb1-9401-44bf-9664-c60524066646",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_test = pheno_test.dropna(subset=['Event', 'Event_time']) #should not try to correct these\n",
    "reads_test = reads_test.T\n",
    "test_ids = pheno_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a338574-f9c2-4f17-8b26-6e4705318d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_full = pd.concat([reads_train, reads_test])\n",
    "pheno_full = pd.concat([pheno_train, pheno_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc6fe8-2536-4273-a873-52acc3dd9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_full = fillNA(pheno_full, index=pheno_full.index) #fast KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621fb12-61bf-42d0-871d-c72758b3caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.merge(reads_full, pheno_full, left_index=True, right_index=True)\n",
    "labels = features.pop('Event')\n",
    "true_labels = labels.copy()\n",
    "#labels.value_counts() # 0 - 4898, 1 - 445 --> highly imbalanced\n",
    "\n",
    "X_train, y_train = features.loc[train_ids], labels[train_ids]\n",
    "X_test, y_test = features.loc[test_ids], labels[test_ids]\n",
    "\n",
    "X_train, X_test = minmax_scale(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd302b1e-ab66-462b-945a-c0ea36792bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = [\n",
    "            'Age', \n",
    "            'BodyMassIndex', \n",
    "            'BPTreatment', \n",
    "            'Smoking', \n",
    "            'PrevalentDiabetes', \n",
    "            'PrevalentHFAIL', \n",
    "            'Event_time', \n",
    "            'SystolicBP', \n",
    "            'NonHDLcholesterol', \n",
    "            'Sex'\n",
    "           ]\n",
    "\n",
    "meta_train = X_train[metadata].copy()\n",
    "rds_train = X_train.drop(metadata, axis=1)\n",
    "\n",
    "meta_test = X_test[metadata].copy()\n",
    "rds_test = X_test.drop(metadata, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35f574-dede-492a-a16a-45681a2c357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_train, AE_test = run_AE(rds_train, rds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055de25-76e9-4d5e-b5c0-d51a4fc252ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ET = meta_train.pop('Event_time')\n",
    "important_cols = run_LASSO(meta_train, ET)\n",
    "important_cols = np.append(important_cols, 'Event_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e08720-32b8-45e7-b51f-80a49f0f47ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train['Event_time'] = ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b6e78-22e7-468f-9ee7-695e4f1780f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_train_df = AE_train.join(meta_train[important_cols])\n",
    "AE_train_df = AE_train_df.set_index(train_ids)\n",
    "\n",
    "AE_test_df = AE_test.join(meta_test[important_cols])\n",
    "AE_test_df = AE_test_df.set_index(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9a546-f340-4a07-ba89-28aae0fed2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AE = pd.concat([AE_train_df, AE_test_df])\n",
    "df_AE['Event'] = true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ec3bf-f8a8-4ac9-8f89-2cce1e73bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_AE.copy()\n",
    "times = features.pop('Event_time')\n",
    "events = features.pop('Event')\n",
    "\n",
    "train_times = times[train_ids]\n",
    "train_events = events[train_ids]\n",
    "y_train = make_structured_array(train_events, train_times)\n",
    "\n",
    "test_times = times[test_ids]\n",
    "test_events = events[test_ids]\n",
    "y_test = make_structured_array(test_events, test_times)\n",
    "\n",
    "X_train = features.loc[train_ids]\n",
    "X_test = features.loc[test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d59f6-4e87-4eb9-aac3-98be482fced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cph_tree = GradientBoostingSurvivalAnalysis(\n",
    "    n_estimators=1000, \n",
    "    random_state=8993624,\n",
    "    loss='coxph',\n",
    "    max_depth=5,\n",
    "    max_features='sqrt',\n",
    "    verbose=1\n",
    "    )\n",
    "est_cph_tree.fit(X_train, y_train)\n",
    "est_cph_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3b97d-8197-48fd-872a-4fbacf6f677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'UTK_Bioinformatics_Submission_1/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e031ee-2d13-4ab9-9cc6-71655a81cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_FOLDER = os.path.isdir(OUTPUT_DIR)\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d1484-4f70-4687-bc77-98705413ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = est_cph_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e22730-8cd5-4908-9dff-c0d595243b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = normalize(y_preds) #ensure range 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5726b-7b13-44fe-83d9-3fd29d967b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'SampleID' : test_ids, 'Score' : y_preds}\n",
    "out_df = pd.DataFrame(data)\n",
    "out_df.to_csv(OUTPUT_DIR+'scores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
